{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page1: Done\n",
      "page2: Done\n",
      "page3: Done\n",
      "page4: Done\n",
      "page5: Done\n",
      "page6: Done\n",
      "page7: Done\n",
      "page8: Done\n",
      "page9: Done\n",
      "page10: Done\n",
      "page11: Done\n",
      "page12: Done\n",
      "page13: Done\n",
      "page14: Done\n",
      "page15: Done\n",
      "page16: Done\n",
      "page17: Done\n",
      "page18: Done\n",
      "page19: Done\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import undetected_chromedriver as uc  # For using Chrome browser\n",
    "from selenium.webdriver.common.by import By  # For locating elements\n",
    "import time  # For adding delays\n",
    "import pandas as pd  # For working with dataframes\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "names, Links , Twiters , Facebooks , Instagrams , Youtubes , descriptions , desc_LastUpdates , Locations = [] , [] , [] , [] , [] , [] , [] , [] , []\n",
    "year_publishings , Languages  , contents = [] , [] , []\n",
    "# Create a ChromeOptions object\n",
    "options = uc.ChromeOptions()\n",
    "\n",
    "# Add the \"--disable-popup-blocking\" argument to the ChromeOptions\n",
    "options.add_argument(\"--disable-popup-blocking\")\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open the target website\n",
    "driver.get('https://directory.projectoasiseurope.com/?page=1&order=-last_published_at')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Accept the cookies\n",
    "driver.find_element(By.XPATH , '/html/body/div[3]/div/div/div[2]/div/a[1]').click()\n",
    "\n",
    "next_page = True\n",
    "\n",
    "page = 0\n",
    "\n",
    "while next_page:\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    container = driver.find_element(By.XPATH , '//*[@id=\"result-items\"]')\n",
    "    listings = container.find_elements(By.XPATH , './div')\n",
    "\n",
    "    for listing in listings:\n",
    "        try :\n",
    "            web_page_link = listing.find_element(By.XPATH , './div/div[2]/div[1]/a').get_attribute('href')\n",
    "        except :\n",
    "            break\n",
    "\n",
    "        web_page = driver.execute_script(\"window.open('{}', '_blank');\".format(web_page_link))\n",
    "\n",
    "        # Switch to the new tab\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "        # Add 1 sec delay\n",
    "        time.sleep(3)\n",
    "\n",
    "        try : \n",
    "            name  = driver.find_element(By.XPATH , '/html/body/div/div/div/div/header/div/div[1]/h1').text\n",
    "            names.append(name)\n",
    "        except :\n",
    "            name = None\n",
    "            names.append(name)\n",
    "\n",
    "        try : \n",
    "            link  = driver.find_element(By.XPATH , '/html/body/div/div/div/div/header/div/div[1]/a').get_attribute('href')\n",
    "            Links.append(link)\n",
    "        except :\n",
    "            link = None\n",
    "            Links.append(link)\n",
    "\n",
    "        try : \n",
    "            twiter  = driver.find_element(By.XPATH , '//i[ @class = \"fab fa-twitter\" ]/parent::a').get_attribute('href')\n",
    "            Twiters.append(twiter)\n",
    "        except :\n",
    "            twiter = None\n",
    "            Twiters.append(twiter)\n",
    "\n",
    "\n",
    "        try : \n",
    "            facebook  = driver.find_element(By.XPATH , '//i[ @class = \"fab fa-facebook-f\" ]/parent::a').get_attribute('href')\n",
    "            Facebooks.append(facebook)\n",
    "        except :\n",
    "            facebook = None\n",
    "            Facebooks.append(facebook)\n",
    "\n",
    "        try : \n",
    "            instagram  = driver.find_element(By.XPATH , '//i[ @class = \"fab fa-instagram\" ]/parent::a').get_attribute('href')\n",
    "            Instagrams.append(instagram)\n",
    "        except :\n",
    "            instagram = None\n",
    "            Instagrams.append(instagram)\n",
    "\n",
    "        try : \n",
    "            youtube  = driver.find_element(By.XPATH , '//i[ @class = \"fab fa-youtube\" ]/parent::a').get_attribute('href')\n",
    "            Youtubes.append(youtube)\n",
    "        except :\n",
    "            youtube = None\n",
    "            Youtubes.append(youtube)\n",
    "\n",
    "        try : \n",
    "            description  = driver.find_element(By.XPATH , '/html/body/div/div/div/div/div').text.rsplit('\\n',1)[0]\n",
    "            descriptions.append(description)\n",
    "        except :\n",
    "            description = None\n",
    "            descriptions.append(description)\n",
    "\n",
    "        try : \n",
    "            LastUpdate = driver.find_element(By.XPATH , '/html/body/div/div/div/div/div').text.rsplit('\\n',1)[1]\n",
    "            index  = LastUpdate.index(\"Last updated:\")\n",
    "            desc_LastUpdate = LastUpdate[index+14::]\n",
    "            desc_LastUpdates.append(desc_LastUpdate)\n",
    "        except :\n",
    "            desc_LastUpdate = None\n",
    "            desc_LastUpdates.append(desc_LastUpdate)\n",
    "\n",
    "        try : \n",
    "            Location = driver.find_element(By.XPATH , '//div [ text() = \"Location:\" ]/following-sibling::div').text\n",
    "            Locations.append(Location)\n",
    "        except :\n",
    "            Location = None\n",
    "            Locations.append(Location)\n",
    "\n",
    "        try : \n",
    "            year_publishing = driver.find_element(By.XPATH , '//div [ text() = \"Year the organisation started publishing:\" ]/following-sibling::div').text\n",
    "            year_publishings.append(year_publishing)\n",
    "        except :\n",
    "            year_publishing = None\n",
    "            year_publishings.append(year_publishing)\n",
    "\n",
    "        try : \n",
    "            language = driver.find_element(By.XPATH , '//div [ text() = \"Languages:\" ]/following-sibling::div').text.replace(' ', ', ')\n",
    "            Languages.append(language)\n",
    "        except :\n",
    "            language = None\n",
    "            Languages.append(language)\n",
    "        \n",
    "        list_of_contents = []\n",
    "        try : \n",
    "            content = driver.find_element(By.XPATH , '//div [ text() = \"Type of content produced by theme:\" ]/following-sibling::div')\n",
    "            content_div = content.find_elements(By.XPATH , './div')\n",
    "            for div in content_div:\n",
    "                list_of_contents.append(div.text)\n",
    "\n",
    "            result_content = ', '.join(list_of_contents)\n",
    "            contents.append( result_content )\n",
    "        except :\n",
    "            contents.append(None)\n",
    "\n",
    "\n",
    "        # Close the new tab\n",
    "        driver.close()\n",
    "\n",
    "        # Switch back to the original tab\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        \n",
    "    page += 1\n",
    "\n",
    "    if page == 20 :\n",
    "        break\n",
    "\n",
    "    try : \n",
    "        nextPage = driver.find_element(By.XPATH , '//li[@class=\"page-item active\"]/following-sibling::li/a ').click()\n",
    "    except :\n",
    "        next_page = False\n",
    "\n",
    "    #print(name , \":\" , link , \":\" , twiter , \":\" , facebook , \":\" , instagram , \":\" , youtube , \":\" , desc_LastUpdate)\n",
    "        \n",
    "    print(f'page{page}: Done')\n",
    "\n",
    "\n",
    "# Create a pandas DataFrame from the scraped data\n",
    "df = pd.DataFrame(list(zip(names, Links, Twiters , Facebooks ,Instagrams , Youtubes , descriptions , \n",
    "                           desc_LastUpdates , Locations , year_publishings , \n",
    "                           Languages  , contents)), columns= [ \"Name\", \"Link\", \"Twiter\" , \"Facebook\"  , \n",
    "                                                              \"Instagram\" , \"Youtube\" , \"Description\"   , \n",
    "                                                              \"LastUpdate\"   , \"Location\"  , \"Year Publishing\"  , \n",
    "                                                              \"Language\" , \"Content\"  ])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"projectoasiseurope.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Quit the browser\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
